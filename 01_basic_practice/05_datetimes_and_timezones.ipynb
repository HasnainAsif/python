{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating date objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "d1, d2, d3 = date(2016, 10, 7), date(2017, 6, 21), date(2016, 6, 21)\n",
    "hurricanes_dates = [d1, d2, d3]\n",
    "print(hurricanes_dates)\n",
    "print(\"access year and weekday: \", hurricanes_dates[0].year, hurricanes_dates[0].weekday())\n",
    "print('min date: ', min(hurricanes_dates)) # returned date is in YYYY-MM-DD format\n",
    "print(\"sorted dates: \", sorted(hurricanes_dates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Weekdays in python: 0 for Monday and 6 for Sunday`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Date and time Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "dt = datetime(2017, 10, 1, 15, 23, 25, 500000) # YYYY, MM, DD, HH, mm, ss, micro-sec\n",
    "# dt = datetime(year=2017, month=10, day=1, hour=15, minute=23, second=25, microsecond=500000)\n",
    "print(\"Date: \", dt)\n",
    "\n",
    "dt_replaced = dt.replace(second=0, microsecond=0) # Replacing parts of a datetime\n",
    "print(\"replaced dt: \", dt_replaced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## timedelta / duration / Time Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = d2 - d1\n",
    "print(\"Difference: \", delta)\n",
    "print(\"Days difference: \", delta.days)\n",
    "print(\"Seconds difference: \", delta.total_seconds())\n",
    "\n",
    "from datetime import timedelta\n",
    "td = timedelta(days=10, seconds=10) # Create a 10 day and 10 seconds timedelta\n",
    "print(f\"Add 10 days to {dt}: \", dt + td)\n",
    "print(f\"Subtract 1 minute from {dt}: \", dt + timedelta(minutes=-1))\n",
    "print(f\"Subtract 1 minute from {dt}: \", dt - timedelta(minutes=1)) # same result as above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Formatted dates and Parsing Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ISO Format of d1: \", d1.isoformat())\n",
    "print(\"String format of d1: \", d1.strftime(\"Year is %Y and day is %d\"))\n",
    "\n",
    "print(\"ISO Format of dt: \", dt.isoformat())\n",
    "print(\"String format of dt: \", dt.strftime(\"%Y/%m/%d %H:%M:%S\"))\n",
    "\n",
    "# Parsing dates\n",
    "from datetime import datetime\n",
    "parsed_dt = datetime.strptime(\"12/30/2017 15:19:13\", \"%m/%d/%Y %H:%M:%S\")\n",
    "print(\"Type: \", type(parsed_dt))\n",
    "print(\"Year and hour: \", parsed_dt.year, parsed_dt.hour)\n",
    "\n",
    "ts = 1514665153.0\n",
    "print(\"Timestamp to date: \", datetime.fromtimestamp(ts)) # convert timestamp to date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with timezone offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "ET = timezone(timedelta(hours=-5)) # US Eastern Standard time zone\n",
    "dt_ET = datetime(2017, 12, 30, 15, 9, 3, tzinfo = ET) # datetime with timezone offset\n",
    "print(\"Date time as per Easter standard timezone: \", dt_ET)\n",
    "\n",
    "# Converting timezone - it will change time also\n",
    "IST = timezone(timedelta(hours=5, minutes=30)) # India Standard time zone\n",
    "print(\"Date time shifted to indian timezone: \", dt_ET.astimezone(IST)) # Convert ET to IST - it will add 10h and 30m.\n",
    "\n",
    "# Replacing timezone - it will not change time\n",
    "print(f\"Timezone replaced to utc timezone for {dt_ET}: \", dt_ET.replace(tzinfo=timezone.utc))\n",
    "print(f\"Timezone replaced to indian timezone for {dt_ET}: \", dt_ET.replace(tzinfo=IST))\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "# Getting timezone offsets from timezone database\n",
    "from dateutil import tz\n",
    "et = tz.gettz('America/New_York') # Eastern time\n",
    "dt_et = datetime(2017, 12, 30, 15, 9, 3, tzinfo = et) # timezone offset from dataset\n",
    "print(\"datetime with Timezone offset: \", dt_et)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting Daylight saving time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "spring_ahead_159am = datetime(2017, 3, 12, 1, 59, 59)\n",
    "print(\"Time 1: \", spring_ahead_159am.isoformat())\n",
    "\n",
    "spring_ahead_3am = datetime(2017, 3, 12, 3, 0, 0)\n",
    "print(\"Time 2: \",spring_ahead_3am.isoformat())\n",
    "\n",
    "print(\"Time difference in seconds: \", (spring_ahead_3am - spring_ahead_159am).total_seconds())\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "EST = timezone(timedelta(hours=-5)) # EST = tz.gettz('US/Eastern')\n",
    "EDT = timezone(timedelta(hours=-4)) # EDT = tz.gettz('US/Eastern')\n",
    "\n",
    "spring_ahead_159am = spring_ahead_159am.replace(tzinfo = EST)\n",
    "print(\"Time, before start of DLS: \", spring_ahead_159am.isoformat())\n",
    "spring_ahead_3am = spring_ahead_3am.replace(tzinfo = EDT)\n",
    "print(\"Time, upon start of DLS: \",spring_ahead_3am.isoformat())\n",
    "\n",
    "# Check time difference without utc timezone\n",
    "print(\"Time difference with DLS: \", (spring_ahead_3am - spring_ahead_159am).total_seconds())\n",
    "\n",
    "# Check time difference with utc timezone\n",
    "spring_ahead_159am = spring_ahead_159am.astimezone(tz.UTC) # switch timezone to utc\n",
    "spring_ahead_3am = spring_ahead_3am.astimezone(tz.UTC) # switch timezone to utc\n",
    "print(f\"Time difference with UTC offset of {spring_ahead_3am} - {spring_ahead_159am}: --> \", (spring_ahead_3am - spring_ahead_159am).total_seconds())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ending Daylight saving time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eastern = tz.gettz('US/Eastern')\n",
    "\n",
    "first_1am = datetime(2017, 11, 5, 1, 0, 0, tzinfo = eastern)\n",
    "print(\"1AM amboguous: \", tz.datetime_ambiguous(first_1am)) # Check if 1am is clocking twice\n",
    "print(\"first_1am: \", first_1am) # don't know; if this time is with -4 or -5 offset. Means, if it comes under DLS or standard timezone\n",
    "\n",
    "second_1am = tz.enfold(first_1am) # Switch '1am' from DLS to standard timezone. If we are sure, this '1am' is of Standard timezone and not DLS.\n",
    "print(\"second 1am: \", second_1am)\n",
    "\n",
    "# Check time difference without utc timezone\n",
    "print(\"Time difference with DLS: \", (second_1am - first_1am).total_seconds()) # wrong time difference\n",
    "\n",
    "# Check time difference without utc timezone\n",
    "first_1am = first_1am.astimezone(tz.UTC) # switch timezone to utc\n",
    "second_1am = second_1am.astimezone(tz.UTC) # switch timezone to utc\n",
    "print(f\"Difference with utc offset of {second_1am} - {first_1am}:--> \", (second_1am - first_1am).total_seconds())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DateTime with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Start date            End date  Start station number  \\\n",
      "0 2017-10-01 15:23:25 2017-10-01 15:26:26                 31038   \n",
      "1 2017-10-01 15:42:57 2017-10-01 17:49:59                 31036   \n",
      "2 2017-10-02 06:37:10 2017-10-02 06:42:53                 31036   \n",
      "\n",
      "                   Start station  End station number  \\\n",
      "0           Glebe Rd & 11th St N               31036   \n",
      "1  George Mason Dr & Wilson Blvd               31036   \n",
      "2  George Mason Dr & Wilson Blvd               31037   \n",
      "\n",
      "                            End station Bike number Member type  \n",
      "0         George Mason Dr & Wilson Blvd      W20529      Member  \n",
      "1         George Mason Dr & Wilson Blvd      W20529      Casual  \n",
      "2  Ballston Metro / N Stuart & 9th St N      W20529      Member  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "rides = pd.read_csv('./datasets/capital-onebike.csv', parse_dates = ['Start date', 'End date']) # Import W20529's rides in Q4 2017\n",
    "# rides['Start date'] = pd.to_datetime(rides['Start date'], format = \"%Y-%m-%d %H:%M:%S\") # use parse_dates or this commented line for 'Start date'\n",
    "\n",
    "print(rides.head(3))\n",
    "# print(rides['Bike number'].unique()) # dataset is of only 1 bike"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rides['Duration'] = rides['End date'] - rides['Start date'] # Create a duration column\n",
    "rides['Duration seconds'] = rides['Duration'].dt.total_seconds()\n",
    "print(rides['Duration seconds'].head(5), end='\\n\\n')\n",
    "\n",
    "print(\"Mean: \", rides['Duration'].mean()) # Average time out of the dock\n",
    "print(\"Sum: \", rides['Duration'].sum()) # Total time out of the dock\n",
    "\n",
    "print(\"Percent of time, out of the dock: \", rides['Duration'].sum() / timedelta(days=91), end='\\n\\n') # Percent of time out of the dock - used 91, because we have data of 91 days only\n",
    "\n",
    "print(\"Average duration per member type: \", rides.groupby('Member type')['Duration seconds'].mean(), sep='\\n')\n",
    "print(\"Average duration by month: \", rides.resample('ME', on = 'Start date')['Duration seconds'].mean(), sep='\\n', end='\\n\\n')\n",
    "\n",
    "print(\"Minimum duration: \", rides['Duration seconds'].min()) # Duration is negative. Upon checking we found out that its because of DLS ending at that day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print ambiguous time\n",
    "\n",
    "Here it looks `Start data` is greater than `End date`. \n",
    "\n",
    "But in realty `End data` is after `Start date` because DLS is ending at this date. and `Start date` falls under DLS timezone and `End date` falls under Standard timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ambiguous value location: \", rides[['Start date', 'End date', 'Member type']].iloc[129], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set timezone to dates\n",
    "\n",
    "`Without setting timezone to 'Start data' and 'End data', we cannot calculate exact duration for DLS switching days `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rides['Start date'] = rides['Start date'].dt.tz_localize('America/New_York') # it gives error because there is one value for which its ambiguous that either its offset is DLS or standard.\n",
    "\n",
    "# seeting ambiguous values with 'Not a Time'\n",
    "rides['Start date'] = rides['Start date'].dt.tz_localize('America/New_York', ambiguous='NaT') # based on our previous knowledge of ambiguous time, We can also set 'ambiguous' values\n",
    "rides['End date'] = rides['End date'].dt.tz_localize('America/New_York', ambiguous='NaT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check duration again after setting timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find duration and min value again\n",
    "rides['Duration'] = rides['End date'] - rides['Start date'] # Create a duration column\n",
    "rides['Duration seconds'] = rides['Duration'].dt.total_seconds()\n",
    "print(\"Minimum duration: \", rides['Duration seconds'].min())\n",
    "\n",
    "print(\"Ambiguous value location: \", rides.iloc[129], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other datatime operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"year: \", rides['Start date'].head(3).dt.year, sep='\\n') # Year of first three rows\n",
    "print(\"Dayname: \", rides['Start date'].head(3).dt.day_name(), sep='\\n') # See weekdays for the first three rows\n",
    "\n",
    "print(rides['End date'].shift(1).head(3)) # Shift the indexes forward one, padding with NaT\n",
    "\n",
    "# Find duration between two rides. i.e; when one ride ended, after how much time second ride started\n",
    "# Find difference of time between Start date and previous ride End date - For this, data should be sorted based on Start date\n",
    "rides['End date shifted'] = rides['End date'].shift(1)\n",
    "rides['time_to_last_ride'] = (rides['Start date'] - rides['End date shifted']).dt.total_seconds()\n",
    "rides[['Start date', 'End date', 'End date shifted', 'time_to_last_ride']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
