{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning of Machine Learning Models\n",
    "\n",
    "* Hyperparameter tuning is the process of `finding the best hyperparameters` for a machine learning model.\n",
    "* `Hyperparameters` are the parameters that are not learned by the model. \n",
    "* They are set before training the model. \n",
    "* The process of hyperparameter tuning is also known as `hyperparameter optimization.`\n",
    "\n",
    "## Why Hyperparameter Tuning is Important?\n",
    "\n",
    "* Hyperparameter tuning is important because the performance of the model is highly dependent on the hyperparameters.\n",
    "* The right choice of hyperparameters can make a huge difference in the performance of the model.\n",
    "* Hyperparameter tuning helps to find the best hyperparameters for the model which results in the best performance.\n",
    "* It helps to improve the performance of the model.\n",
    "* It helps to avoid overfitting and underfitting.\n",
    "* It helps to make the model more robust.\n",
    "\n",
    "## Techniques for Hyperparameter Tuning\n",
    "\n",
    "There are several techniques for hyperparameter tuning. Some of the most popular techniques in Scikit-learn are:\n",
    "* Grid Search\n",
    "* Random Search\n",
    "* Successive Halving\n",
    "  * Halving Grid Search\n",
    "  * Halving Random Search \n",
    "\n",
    "**ARTICLE**: https://scikit-learn.org/stable/modules/grid_search.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV #, HalvingGridSearchCV, HalvingRandomSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Hyperparameter Tuning with scikit-learn on the Tips Dataset\n",
    "# This notebook demonstrates how to perform hyperparameter tuning using scikit-learn's GridSearchCV on the Tips dataset.\n",
    "\n",
    "\n",
    "# Load and Explore the Data\n",
    "tips = sns.load_dataset('tips')\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Preprocess the Data\n",
    "# Convert categorical variables using one-hot encoding\n",
    "tips_encoded = pd.get_dummies(tips, drop_first=True)\n",
    "print(tips_encoded.head())\n",
    "\n",
    "# Define features and target variable\n",
    "X = tips_encoded.drop('tip', axis=1)\n",
    "y = tips_encoded['tip']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameter Tuning with GridSearchCV\n",
    "# Define the model\n",
    "rf = RandomForestRegressor(random_state=42) \n",
    "print(\"Parameter that could be tuned: \", rf.get_params()) # list all hyperparameters\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200], # length = 3\n",
    "    'max_depth': [None, 10, 20, 30], # length = 4\n",
    "    'min_samples_split': [2, 5, 10], # length = 3\n",
    "    # 'min_samples_leaf': [1, 2, 3], \n",
    "    # 'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "# total combination of parameters = 3 * 4 * 3 = 36 combinations. It means model will be trained 36 times.\n",
    "# GridSearchCV will evaluate all combinations of these parameters. i.e; 36\n",
    "# RandomizedSearchCV will evaluate a random subset of these combinations i.e; 10 or 20 combinations which are less than 36. Its more efficient for large parameter grids\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5, # cross-validate 5 times, means: 36 combinations will be evaluated 5 times each. total = 36 * 5 = 180 model evaluations\n",
    "    scoring='neg_mean_squared_error', # scoring metric for regression tasks. Other scoring metrics: roc_auc, accuracy\n",
    "    # n_jobs=-1,\n",
    "    # verbose=1,\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best Parameters and Evaluation\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Score (Negative MSE): {grid_search.best_score_:.2f}\") # Best score is the negative mean squared error, so we take the absolute value\n",
    "print(f\"Best Score (MSE): {-grid_search.best_score_:.2f}\")\n",
    "\n",
    "# Predict on test set\n",
    "best_rf = grid_search.best_estimator_ # best fitted model\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error on Test Set: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Preprocess the Data\n",
    "# Convert categorical variables using one-hot encoding\n",
    "tips_encoded = pd.get_dummies(tips, drop_first=True)\n",
    "\n",
    "# Define features and target variable\n",
    "X = tips_encoded.drop('tip', axis=1)\n",
    "y = tips_encoded['tip']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameter Tuning with GridSearchCV\n",
    "# Define the model\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10, # Number of parameters to pick from 36 combinations. remaining combinations will be randomly selected. i.e; 10 combinations will be evaluated\n",
    "    cv=5, # cross-validate 5 times, means: 10 combinations will be evaluated 5 times each. total = 10 * 5 = 50 model evaluations\n",
    "    # n_jobs=-1,\n",
    "    scoring='neg_mean_squared_error'\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best Parameters and Evaluation\n",
    "print(f\"Best Parameters: {random_search.best_params_}\")\n",
    "print(f\"Best Score (Negative MSE): {random_search.best_score_:.2f}\")\n",
    "\n",
    "# Predict on test set\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error on Test Set: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import RandomizedSearchCV, HalvingGridSearchCV, HalvingRandomSearchCV\n",
    "\n",
    "# Initialize HalvingGridSearchCV\n",
    "halving_grid_search = HalvingGridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5, # cross-validate 5 times, means: 36 combinations will be evaluated 5 times each. total = 36 * 5 = 180 model evaluations\n",
    "    factor=2, # Halving factor, means: each iteration will halve the number of candidates\n",
    "    # resource='n_estimators',\n",
    "    scoring='neg_mean_squared_error'\n",
    ")\n",
    "\n",
    "# Fit HalvingGridSearchCV\n",
    "halving_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best Parameters and Evaluation\n",
    "print(f\"Best Parameters: {halving_grid_search.best_params_}\")\n",
    "\n",
    "# Predict on test set\n",
    "best_rf = halving_grid_search.best_estimator_\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error on Test Set: {mse:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
