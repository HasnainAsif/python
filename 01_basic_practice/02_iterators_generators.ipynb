{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterators, List Compression and Generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterators using for loop and iter method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flash = ['jay garrick', 'barry allen', 'wally west', 'bart allen']\n",
    "\n",
    "for person in flash:\n",
    "    print(person)\n",
    "\n",
    "print('----------------------- LOOP END ------------------------')\n",
    "\n",
    "# Create an iterator for flash\n",
    "superhero = iter(flash)\n",
    "\n",
    "# Print each item from the iterator\n",
    "print(next(superhero))\n",
    "print(next(superhero))\n",
    "print(next(superhero))\n",
    "print(next(superhero))\n",
    "# print(next(superhero)) # calling it again will throw error, because all elments have been iterated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flash = ['jay', 'barry', 'wally', 'bart']\n",
    "# print(*flash) # print all elements at once\n",
    "superhero = iter(flash)\n",
    "print(*superhero) # print all elements at once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterator using range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an iterator for range(3)\n",
    "small_value = iter(range(3))\n",
    "\n",
    "print(next(small_value))\n",
    "print(next(small_value))\n",
    "print(next(small_value))\n",
    "# print(next(small_value)) # calling it again throw error, because\n",
    "\n",
    "# for num in range(3):\n",
    "#     print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterators are helpful when data is too large to load at once in memory. It will load data in memory; chunk by chunk; by using \"next\" function\n",
    "\n",
    "small_value = iter(range(10**100))\n",
    "print(next(small_value))\n",
    "print(next(small_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enumerates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutants = ['charles xavier', 'bobby drake', 'kurt wagner', 'max eisenhardt', 'kitty pryde']\n",
    "\n",
    "# Create a list of tuples\n",
    "mutant_list = list(enumerate(mutants))\n",
    "\n",
    "print(mutant_list) # Print the list of tuples\n",
    "\n",
    "# Unpack and print the tuple pairs\n",
    "for index1, value1 in enumerate(mutants):\n",
    "    print(index1, value1)\n",
    "\n",
    "print('---------------------- END ------------------------')\n",
    "\n",
    "# Change the start index\n",
    "for index2, value2 in enumerate(mutants, start=10):\n",
    "    print(index2, value2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zip and Unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutants = ['charles_xavier', 'bobby_drake', 'kurt_wagner', 'max_eisenhardt', 'kitty_pryde']\n",
    "aliases = ['prof_x', 'iceman', 'nightcrawler', 'magneto', 'shadowcat']\n",
    "\n",
    "# Create a list of tuples\n",
    "mutant_data = list(zip(mutants,aliases))\n",
    "mutant_data_dictionary = dict(zip(mutants,aliases))\n",
    "\n",
    "print(\"mutant_data_dictionary: \", mutant_data_dictionary)\n",
    "print(\"mutant_data: \", mutant_data) # Print the list of tuples\n",
    "print('-----------------------------------------')\n",
    "\n",
    "mutant_zip = zip(mutants,aliases) # Create a zip object\n",
    "\n",
    "print(mutant_zip) # Print the zip object\n",
    "print('-----------------------------------------')\n",
    "\n",
    "# Unpack the zip object and print the tuple values\n",
    "for value1, value2 in mutant_zip:\n",
    "    print(value1, value2)\n",
    "\n",
    "###########################################################################################################\n",
    "print(\"###################################################################################################\")\n",
    "z1 = zip(mutants, aliases)\n",
    "\n",
    "print(*z1) # Print the tuples in z1 by unpacking with *\n",
    "\n",
    "z1 = zip(mutants, aliases) # Re-create a zip object from mutants, because previous z1 is empty now\n",
    "\n",
    "result1, result2 = zip(*z1) # 'Unzip' the tuples\n",
    "\n",
    "# Check if unpacked tuples are equivalent to original tuples\n",
    "print(result1 == mutants)\n",
    "print(result2 == aliases)\n",
    "\n",
    "print(type(result1), type(mutants))\n",
    "print(list(result1))\n",
    "print(list(result1) == mutants)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching data chunk by chunk and process\n",
    "\n",
    "`This way, all data will not be loaded on memory at once. By rather, it will be leaded chunk by chunk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "add = 0\n",
    "\n",
    "# Iterate over the file chunk by chunk - fetch dataframe of 3 records at a time\n",
    "for chunk in pd.read_csv('../00_datasets/medals.csv', chunksize=3, index_col=0):\n",
    "    print(chunk, end='\\n----------------------------------------\\n')\n",
    "    gold_series_with_int_type = chunk['Gold']\n",
    "    add += gold_series_with_int_type.sum()\n",
    "\n",
    "print(add)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "add = 0\n",
    "\n",
    "# Get dataframe chunk by chunk - fetch dataframe of 3 records at a time\n",
    "df_reader = pd.read_csv('../00_datasets/medals.csv', chunksize=3, index_col=0) # returns a generator\n",
    "print(next(df_reader), end='\\n----------------------------------------\\n')\n",
    "print(next(df_reader), end='\\n----------------------------------------\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Comprehensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [1,2,3,4]\n",
    "squared_nums = [num ** 2 for num in nums]\n",
    "print(\"squared_nums: \", squared_nums)\n",
    "\n",
    "## Another way to above\n",
    "# squares = [i ** 2 for i in range(1, 5)]\n",
    "# print(squares)\n",
    "\n",
    "## Another way to above\n",
    "# squared_nums_using_map = map(lambda num: num ** 2 , nums)\n",
    "# print(list(squared_nums_using_map))\n",
    "\n",
    "################################### Nested list ###########################################\n",
    "# # Simple Way\n",
    "# arr = []\n",
    "# for i in range(0, 3):\n",
    "#     for j in range(0, 2):\n",
    "#         arr.append((i, j))\n",
    "# print(arr)\n",
    "\n",
    "## Using List Comprehension\n",
    "arr_new = [ (i, j) for i in range(0, 3) for j in range(0, 2)]\n",
    "print(\"arr_new: \", arr_new)\n",
    "\n",
    "arr_new_advance = [ [(i, j) for i in range(0, 3)] for j in range(0, 2)]\n",
    "print(\"arr_new_advance: \", arr_new_advance)\n",
    "\n",
    "#################################### List Comprehension with conditions ###############################\n",
    "rand_nums = [0,5,3,7,6,2,10,21] \n",
    "squared_evenNums = [(num, num ** 2) for num in rand_nums if num % 2 == 0]\n",
    "print(\"squared_evenNums: \", squared_evenNums)\n",
    "\n",
    "evens_with_null_odds = [num if num % 2 == 0 else 0 for num in rand_nums]\n",
    "print(\"evens_with_null_odds: \", evens_with_null_odds)\n",
    "\n",
    "#################################### Create dictionary using List Comprehension ###############################\n",
    "rand_nums1 = [0,5,3,7,6,2,10,21] \n",
    "squared_evenNums_dict = { num: num ** 2 for num in rand_nums1}\n",
    "print(\"squared_evenNums_dict: \", squared_evenNums_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_nums = [0,5,3,7,6,2,10,21,22,26,82,31] \n",
    "\n",
    "# Generator expression - Its syntax is similar to list comprehension\n",
    "even_nums = (num for num in rand_nums if num % 2 == 0)\n",
    "print(even_nums)\n",
    "print(next(even_nums))\n",
    "print(next(even_nums))\n",
    "print(next(even_nums))\n",
    "print('----------- ITERATOR END ---------------')\n",
    "## print rest of the values using for loop\n",
    "for value in even_nums:\n",
    "    print(value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator Functions\n",
    "\n",
    "`It will not load all data at once into memory. Instead, it will load data step by step`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_nums = [0,5,3,7,6,2,10,21,22,26,82,31] \n",
    "\n",
    "# Define generator function get_lengths\n",
    "def get_evens(input_list):\n",
    "    \"\"\"Generator function that yields the\n",
    "    even numbers in input_list.\"\"\"\n",
    "\n",
    "    # Yield the even numbers only\n",
    "    for person in input_list:\n",
    "        if(person % 2 == 0):\n",
    "            yield person\n",
    "\n",
    "# Print the values generated by get_lengths()\n",
    "for value in get_evens(rand_nums):\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real World Example for Zip and List Compression\n",
    "\n",
    "`Convert arrays to Data Frame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def lists2dict(feature_names, row_list):\n",
    "    zipped_values = zip(feature_names, row_list)\n",
    "    dict_values = dict(zipped_values)\n",
    "    return dict_values\n",
    "\n",
    "feature_names = ['name', 'age', 'fare']\n",
    "row_lists = [['John', '29', '550'], ['Doe', '35', '435'], ['Cena', '40', '450']]\n",
    "\n",
    "# Turn list of lists into list of dicts\n",
    "list_of_dicts = [lists2dict(feature_names, sublist) for sublist in row_lists]\n",
    "\n",
    "df = pd.DataFrame(list_of_dicts) # Turn list of dicts into a DataFrame\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read large files, step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is just for educational purpose. Otherwise, file alias is already a pre-defined generator\n",
    "def read_large_file(file_object):\n",
    "    \"\"\"A generator function to read a large file lazily.\"\"\"\n",
    "\n",
    "    # Loop indefinitely until the end of the file\n",
    "    while True:\n",
    "        data = file_object.readline() # Read a line from the file\n",
    "        # Break if this is the end of the file\n",
    "        if not data:\n",
    "            break\n",
    "        \n",
    "        yield data # Yield the line of data\n",
    "        \n",
    "# Open a connection to the file\n",
    "with open('../00_datasets/medals.csv') as file:\n",
    "\n",
    "    # Create a generator object for the file: gen_file\n",
    "    gen_file = read_large_file(file)\n",
    "\n",
    "    # Print the first three lines of the file\n",
    "    print(next(gen_file))\n",
    "    print(next(gen_file))\n",
    "    print(next(gen_file))\n",
    "    \n",
    "    print('------------- GENERATOR LOOOPING START HERE -----------------')\n",
    "    # Iterate rest of lines from generator\n",
    "    for line in gen_file:\n",
    "        print(line)\n",
    "\n",
    "print('##########################################################################################')\n",
    "################################# Simple way of above function ########################################\n",
    "# file1 is pre-defined generator\n",
    "with open('../00_datasets/medals.csv') as file1:\n",
    "    # Read file line by line\n",
    "    print(file1.readline())\n",
    "    print(file1.readline())\n",
    "    print(file1.readline())\n",
    "    print(file1.readline())\n",
    "    \n",
    "    print('------------- GENERATOR LOOOPING START HERE -----------------')\n",
    "    # Iterate rest of lines from generator\n",
    "    for line in file1:\n",
    "        print(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a column into only 1s chunk of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reader = pd.read_csv('../00_datasets/titanic.csv', chunksize=100) # Initialize reader object\n",
    "\n",
    "df_reader_val = next(df_reader) # Get the first DataFrame chunk\n",
    "print(df_reader_val.head())\n",
    "\n",
    "print('--------------------------------------------------------------------')\n",
    "\n",
    "df_male = df_reader_val[df_reader_val['sex'] == 'male'].copy() # filter by gender\n",
    "\n",
    "age_fare = zip(df_male['age'], df_male['fare']) # Zip DataFrame columns of interest\n",
    "age_fare_list = list(age_fare) # Turn zip object into list\n",
    "print(\"age_fare_list: \", age_fare_list)\n",
    "print('--------------------------------------------------------------------')\n",
    "\n",
    "# Use list comprehension to create new DataFrame column\n",
    "df_male['int_fare'] = [int(fare) for age, fare in age_fare_list]\n",
    "# df_male['int_fare'] = df_male['fare'].astype(int)\n",
    "print(df_male[['survived','sex','age', 'fare', 'int_fare']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a column into dataframe, chunk by chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      age     sex\n",
      "0    22.0    male\n",
      "1    38.0  female\n",
      "2    26.0  female\n",
      "3    35.0  female\n",
      "4    35.0    male\n",
      "..    ...     ...\n",
      "886  27.0    male\n",
      "887  19.0  female\n",
      "888   NaN  female\n",
      "889  26.0    male\n",
      "890  32.0    male\n",
      "\n",
      "[891 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_reader = pd.read_csv('../00_datasets/titanic.csv', chunksize=100) # Initialize reader object\n",
    "\n",
    "titanic_male = pd.DataFrame() # Initialize empty DataFrame\n",
    "\n",
    "# loop through each chunk, one-by-one\n",
    "for df_reader_val in df_reader:\n",
    "    df_male = df_reader_val[df_reader_val['sex'] == 'male'].copy() # filter by gender\n",
    "\n",
    "    age_fare = zip(df_male['age'], df_male['fare']) # Zip DataFrame columns of interest\n",
    "    age_fare_list = list(age_fare) # Turn zip object into list\n",
    "    # print(\"age_fare_list: \", age_fare_list)\n",
    "    # print('--------------------------------------------------------------------')\n",
    "\n",
    "    # Use list comprehension to create new DataFrame column\n",
    "    df_male['int_fare'] = [int(fare) for age, fare in age_fare_list]\n",
    "    # print(df_male[['survived','sex','age', 'fare', 'int_fare']])\n",
    "\n",
    "    titanic_male = pd.concat([titanic_male, df_male]) # Concatenate DataFrame chunk to the end of data\n",
    "\n",
    "print(titanic_male.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
