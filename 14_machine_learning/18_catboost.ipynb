{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CatBoost Algorithm**\n",
    "\n",
    "One the best algorithms for `classification` tasks\n",
    "\n",
    "- `CatBoost` is a state-of-the-art open-source gradient boosting on decision trees library.\n",
    "- It is developed by Yandex researchers and engineers, and is used for search, recommendation systems, personal assistant, self-driving cars, weather prediction and many other tasks at Yandex and in other companies.\n",
    "- It is in Python and it is designed to be integrated in data science pipelines.\n",
    "- It provides state-of-the-art results and it is powerful in handling categorical features.\n",
    "- Do we need to encode categorical features before training the model? `No, CatBoost does not require it.`\n",
    "- It is efficient. It provides a fast and scalable multi-threaded implementation of the algorithm.\n",
    "- It provides powerful visualization tools to understand the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install catboost -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data import titanic\n",
    "df = sns.load_dataset('titanic')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre-processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing values using knn imputers in age\n",
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df['age'] = imputer.fit_transform(df[['age']])\n",
    "\n",
    "# impute embarked missing values using pandas\n",
    "df['embarked'] = df['embarked'].fillna(df['embarked'].mode()[0])\n",
    "df['embark_town'] = df['embark_town'].fillna(df['embark_town'].mode()[0])\n",
    "# drop deck column\n",
    "df.drop('deck', axis=1, inplace=True)\n",
    "\n",
    "# df missing values\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['alive'], axis=1) # dropping it, because we are going to predict survived. --> survived and alive both are same\n",
    "\n",
    "# convert each category/object column to category\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "# add this as a new column in the dataframe\n",
    "df[categorical_cols] = df[categorical_cols].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into X and y\n",
    "X = df.drop('survived', axis=1)\n",
    "y = df['survived']\n",
    "\n",
    "# split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# run the catboost classifier\n",
    "model = CatBoostClassifier(iterations=1000, # means: 1000 trees\n",
    "                           learning_rate=0.001, # learning rate means how much to change the model in response to the estimated error each time the model weights are updated\n",
    "                           depth=3, # depth of the tree\n",
    "                           loss_function='Logloss', # Logloss is used for binary classification problems\n",
    "                           eval_metric='Accuracy',\n",
    "                           random_seed=42,\n",
    "                           verbose=False) # verbose=False means no output during training\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train, cat_features=categorical_cols.tolist()) # cat_features are the categorical columns in the dataset. We are telling model, there is no need to encode these columns, it will handle them internally.\n",
    "\n",
    "# predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# evaluate the model\n",
    "print(f'Accuracy Score: {accuracy_score(y_test, y_pred)}')\n",
    "print(f'Confusion Matrix: \\n {confusion_matrix(y_test, y_pred)}')\n",
    "print(f'Classification Report: \\n {classification_report(y_test, y_pred)}')\n",
    "\n",
    "# plot confusion matrix\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='viridis')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Alert:\n",
    "- In this notebook, you will learn how to use CatBoost algorithm to make predictions.\n",
    "- Make the same prediction for any dataset and submit the results via discord."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance - this will show the importance of each feature in the model\n",
    "feature_importance = model.get_feature_importance(prettified=True)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importances', y='Feature Id', data=feature_importance)\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
